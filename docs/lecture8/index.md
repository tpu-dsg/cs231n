# Lecture 8: AttentionとTransformers

- [Attention](./attention.md)（[原文](https://cs231n.github.io/attention/)）

## 扱う内容

- Self-Attention
- Transformers

## 参考資料

- [講義スライド](https://cs231n.stanford.edu/slides/2024/lecture_8.pdf)
- [Attention is All You Need](https://arxiv.org/abs/1706.03762)
- [Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- ViT: Transformers for Image Recognition
    - [論文](https://arxiv.org/abs/2010.11929)
    - [Blog](https://research.google/blog/transformers-for-image-recognition-at-scale/?m=1)
    - [動画](https://www.youtube.com/watch?v=TrdevFK_am4)